# Explanation &ndash; Timing

*Please ensure you have read the [Summary and Definitions](2.1._Summary_and_Definitions.md) before considering the further detail covered by this page.*

The model for a `Flow` associates time information with the data (each `Entry` associates a `Time Value` with a `Data Object`). This time information serves a number of purposes:
* A `Time Value` can be used to identify a `Data Object` within a time series of `Data Object`s.
* `Time Value`s define an ordering relationship on the data. An event happens before another event if the `Time Value` of the first event is less than the second event.
* `Time Value`s provide an offset relationship between `Data Object`s. The time difference between events is the time that elapsed between those events.

Note: Further discussion of `Time Value` uniqueness within a `Flow` can be found in [4.0. Appendix - Commentary](4.0.%20Appendix%20-%20Commentary.md#further-work).

In certain scenarios the `Time Value`s have a relation to the real world time as we perceive it; and these `Time Value`s might indicate when the events happened.

Time is assumed to be linear. Given that a `Time Value` is measured as the number of seconds relative to a zero-point, the time elapsed between two `Time Value`s is given by subtracting one measurement from the other (assuming they use the same zero-point).


## `Time Context`s

The entity `Time Context` is intended to be very close in meaning to the term "timeline" that is used casually in relation to audio or video editing to describe the common time grid onto which media clips are placed.

Some example `Time Context`s:
* **Example 1**: A studio distributes a clock signal using PTP such that all capture devices are synchronised and have their zero-point set to the SMPTE epoch at 1970\-01\-01 00:00:00 TAI.
* **Example 2**: A camera captures audio and video, synchronised using a local clock signal, and sets the zero-point to the start of the capture.
* **Example 3**: An MXF Package defines a zero-point (origin) and establishes the synchronisation relationship between the contained Tracks.
* **Example 4**: A media file containing video and audio sets a zero-point at the start of the presentation. If there are any pre-charge video frames or priming audio samples then their `Time Value` is before the zero-point.

A number of `Flow`s might use a single `Time Context`. But this `Time Context` is not necessarily the primary or intended synchronisation relationship.

For example, a Studio and a contribution from an Outside Broadcast share the `Time Context` defined as TAI time from the SMPTE epoch; that is, the `Time Value`s in the Studio and Outside Broadcast are the same when content is captured at the same instant in time. However, it is likely that a re-timing component will be used at the Studio boundary to re-time the Outside Broadcast content so that it can be directly mixed with the studio content. So, content is sometimes re-timed even when it uses a shared `Time Context`. Refer to [3.3. Media Production Chains](3.3._Media_Production_Chains.md) for more details on this example.


## Representation of `Time Value`s

A `Time Value` representation must provide sufficient information for the number of seconds it represents to be determined.

**Example 1**: A `Time Value` representation consists of a count value and a time unit. All `Time Value`s in this `Flow` use the same time unit. The count alone can be used to compare with other `Time Value`s in the same `Flow`. The time unit is needed to allow it to be compared with `Time Value`s in other `Flow`s.

A `Time Value` representation must have sufficient accuracy to allow relationships such as ordering and offsets to be established.

**Example 2**: A transfer for a final presentation includes an H.264 encoded video `Flow` and AAC encoded audio `Flow` that use a millisecond-resolution `Time Value` representation. This accuracy is sufficient for a final presentation context where sub-millisecond timing synchronisation errors are not a problem.

**Example 3**: A production chain consists of many operations that modify the timing information. It is important in this scenario that the timing errors are null or close to null to avoid the errors accumulating to an extent that they become an issue at the final presentation stage.

A `Time Value` representation can consist of a number of elements such as count, units, seconds, rate, timescale, etc. These elements can be communicated together with the media (in-band) or not (out-of-band). The specific requirements of the application determine which elements are used for a `Time Value` representation and how they are communicated.

**Example 4**: An audio `Flow Representation` might encode a `Time Value` as follows:

* A count of 2 is provided in-band with the media
* The units are given as 1/48000 seconds and are stored in a `Flow` metadata database

**Example 5**: An audio `Flow Representation` might encode a `Time Value` as follows:

* A count of 42 is provided
* The units are given as microseconds
* The media rate is indicated to be 48 kHz
* Systems are required to take into account the media rate when determining the precise `Time Value` at which a `Data Object` is located. The `Data Object` is considered to be located at the closest media rate tick.

In Examples 4 and 5 different approaches are taken to encoding the `Time Value`s. However, each of the `Time Value` representations can be losslessly converted into the other &ndash;  the result is that the `Data Object`s are at the same `Time Value`s in these two examples. Therefore, these two `Flow Representation`s could belong to the same `Flow`. Note that if the media rate in Example 5 is not taken into account then the `Data Object`s are at slightly different `Time Value`s (41.666â€¦ vs 42 microseconds) and so the two `Flow Representation`s cannot belong to the same `Flow`.

A `Time Value` is used to identify a `Data Object` within a time series of `Data Object`s. There are different approaches that can be taken to de-reference a time reference to a `Data Object`. For example:

**Example 6**: A store uses a frame count and a media rate to represent the `Time Value`s in a `Flow`. A user requests a `Data Object` at a given millisecond count. The store converts the millisecond count to the nearest frame count using the media rate and then compares the result with the `Time Value` representations in the store.
